<!DOCTYPE html>
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<link rel="shortcut icon" href="https://chaelist.github.io/assets/images/cat.png" type="image/x-icon">
<link rel="stylesheet" href="https://chaelist.github.io/assets/css/just-the-docs-default.css"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-QJ6H6890X3"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-QJ6H6890X3'); </script> <script type="text/javascript" src="https://chaelist.github.io/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="https://chaelist.github.io/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1">
<title>Deep Learning 기초 | chaelist</title>
<meta name="generator" content="Jekyll v4.2.1">
<meta property="og:title" content="Deep Learning 기초">
<meta property="og:locale" content="en_US">
<meta name="description" content="chaelist’s blog">
<meta property="og:description" content="chaelist’s blog">
<link rel="canonical" href="https://chaelist.github.io/docs/ml_basics/deep_learning/">
<meta property="og:url" content="https://chaelist.github.io/docs/ml_basics/deep_learning/">
<meta property="og:site_name" content="chaelist">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Deep Learning 기초"> <script type="application/ld+json"> {"description":"chaelist’s blog","url":"https://chaelist.github.io/docs/ml_basics/deep_learning/","@type":"WebPage","headline":"Deep Learning 기초","@context":"https://schema.org"}</script><script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewbox="0 0 24 24"><title>Link</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewbox="0 0 24 24"><title>Search</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewbox="0 0 24 24"><title>Menu</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewbox="0 0 24 24"><title>Expand</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewbox="0 0 24 24"><title>Document</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar">
<div class="site-header"> <a href="https://chaelist.github.io/" class="site-title lh-tight"> chaelist </a> <a href="#" id="menu-button" class="site-button"> <svg viewbox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a>
</div>
<nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list">
<li class="nav-list-item"><a href="https://chaelist.github.io/" class="nav-list-link">Home</a></li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/python_basics" class="nav-list-link">Python 기초</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/python_basics/numbers_list_string/" class="nav-list-link">Numbers, List, String</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/python_basics/dictionary_tuple_set/" class="nav-list-link">Dictionary, Tuple, Set</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/python_basics/controlflow/" class="nav-list-link">Control Flow (제어문)</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/python_basics/function_module/" class="nav-list-link">Function &amp; Module</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/data_handling" class="nav-list-link">Data Handling</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/file_input_output/" class="nav-list-link">파일 읽고 쓰기</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/file_folder_handling/" class="nav-list-link">파일 &amp; 폴더 다루기</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/regular_expressions/" class="nav-list-link">Regular Expressions</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/useful_functions/" class="nav-list-link">유용한 Python 내장함수</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/datetime/" class="nav-list-link">Datetime 다루기</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/numpy" class="nav-list-link">Numpy</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/numpy/numpy_basics/" class="nav-list-link">Numpy 기초</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/numpy/numpy_arithmetics/" class="nav-list-link">Numpy 연산과 통계</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/pandas" class="nav-list-link">Pandas</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_basics/" class="nav-list-link">Pandas 기초</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_data_modifying/" class="nav-list-link">Pandas 데이터 가공</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_data_analysis/" class="nav-list-link">Pandas 데이터 분석</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_merge_group/" class="nav-list-link">Pandas 데이터 결합 &amp; 요약</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_str_dt_con/" class="nav-list-link">Pandas str, dt, 조건문</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/visualization" class="nav-list-link">데이터 시각화</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/visualization/pandas_plot/" class="nav-list-link">Pandas plot() 함수</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/visualization/seaborn/" class="nav-list-link">Seaborn</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/visualization/matplotlib/" class="nav-list-link">Matplotlib</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/visualization/plotly/" class="nav-list-link">Plotly</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/webscraping" class="nav-list-link">Web Scraping</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/requests_beautifulsoup/" class="nav-list-link">Requests &amp; BeautifulSoup</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/selenium/" class="nav-list-link">Selenium</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/image_api/" class="nav-list-link">Image 수집 &amp; API 활용</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/twitter_api/" class="nav-list-link">Twitter 데이터 수집</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/app_review/" class="nav-list-link">App Review 수집</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/text_analysis" class="nav-list-link">Text 분석</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/text_analysis/english_text/" class="nav-list-link">빈도 분석 (English)</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/text_analysis/korean_text/" class="nav-list-link">빈도 분석 (한글)</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/network_analysis" class="nav-list-link">Network Analysis</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/network_analysis/network_basics/" class="nav-list-link">Network Analysis 기초</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/network_analysis/social_network/" class="nav-list-link">Social Network Analysis</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/network_analysis/semantic_network/" class="nav-list-link">Semantic Network Analysis</a></li>
</ul>
</li>
<li class="nav-list-item active">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/ml_basics" class="nav-list-link">Machine Learning 기초</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_basics/linear_regression/" class="nav-list-link">기초 &amp; Linear Regression</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_basics/classification1/" class="nav-list-link">Classification 1</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_basics/classification2/" class="nav-list-link">Classification 2</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_basics/clustering/" class="nav-list-link">Clustering</a></li>
<li class="nav-list-item active"><a href="https://chaelist.github.io/docs/ml_basics/deep_learning/" class="nav-list-link active">Deep Learning 기초</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/ml_advanced" class="nav-list-link">Machine Learning 심화</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_advanced/regularization/" class="nav-list-link">Regularization</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_advanced/preprocessing/" class="nav-list-link">데이터 전처리</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_advanced/model_selection/" class="nav-list-link">Model Selection</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/ml_application" class="nav-list-link">Machine Learning 응용</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/sentiment_analysis/" class="nav-list-link">영화 리뷰 감성 분석</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/news_clustering/" class="nav-list-link">뉴스 기사 Clustering</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/time_series/" class="nav-list-link">시계열 데이터 예측</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/topic_modeling/" class="nav-list-link">Topic Modeling (LDA)</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/logistics/" class="nav-list-link">물류 최적화</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/image_processing/" class="nav-list-link">이미지 / 동영상 처리</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/sql" class="nav-list-link">SQL</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/select_basics/" class="nav-list-link">데이터 조회 기초</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/select_advanced/" class="nav-list-link">데이터 조회 심화</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/join_subq_view/" class="nav-list-link">조인, 서브쿼리, 뷰</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/db_table_create/" class="nav-list-link">데이터베이스 &amp; 테이블 구축</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/modify_table/" class="nav-list-link">테이블 가공</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/foreign_key_pymysql/" class="nav-list-link">Foreign Key &amp; Python 연결</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/kaggle" class="nav-list-link">Kaggle Dataset EDA</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/youtube_trending/" class="nav-list-link">YouTube Trending Videos</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/amazon_bestsellers/" class="nav-list-link">Amazon Bestselling Books</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/customer_churn/" class="nav-list-link">Telco Customer Churn</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/kiva_crowdfunding/" class="nav-list-link">Kiva Crowdfunding 1</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/kiva_crowdfunding2/" class="nav-list-link">Kiva Crowdfunding 2</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/stem_salaries/" class="nav-list-link">STEM Salaries 1</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/stem_salaries2/" class="nav-list-link">STEM Salaries 2</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/uk_ecommerce/" class="nav-list-link">UK Ecommerce Data 1</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/uk_ecommerce2/" class="nav-list-link">UK Ecommerce Data 2</a></li>
</ul>
</li>
</ul></nav><footer class="site-footer"></footer>
</div>
<div class="main" id="top">
<div id="main-header" class="main-header"><div class="search">
<div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search chaelist" aria-label="Search chaelist" autocomplete="off"> <label for="search-input" class="search-label"><svg viewbox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
</div>
<div id="search-results" class="search-results"></div>
</div></div>
<div id="main-content-wrap" class="main-content-wrap">
<nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list">
<li class="breadcrumb-nav-list-item"><a href="https://chaelist.github.io/docs/ml_basics">Machine Learning 기초</a></li>
<li class="breadcrumb-nav-list-item"><span>Deep Learning 기초</span></li>
</ol></nav><div id="main-content" class="main-content" role="main">
<h1 class="no_toc" id="deep-learning-기초"> <a href="#deep-learning-%EA%B8%B0%EC%B4%88" aria-labelledby="deep-learning-기초" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Deep Learning 기초</h1>
<p><br></p>
<details open=""> <summary class="text-delta"> Table of contents </summary><ol id="markdown-toc">
<li>
<a href="#%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EC%9D%B4%EB%A1%A0" id="markdown-toc-인공신경망-이론">인공신경망 이론</a><ol>
<li><a href="#neural-network%EC%9D%98-%EA%B5%AC%EC%A1%B0" id="markdown-toc-neural-network의-구조">Neural network의 구조</a></li>
<li><a href="#%EA%B0%80%EC%84%A4%ED%95%A8%EC%88%98%EC%99%80-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98" id="markdown-toc-가설함수와-손실함수">가설함수와 손실함수</a></li>
<li><a href="#%ED%99%9C%EC%84%B1-%ED%95%A8%EC%88%98" id="markdown-toc-활성-함수">활성 함수</a></li>
</ol>
</li>
<li>
<a href="#keras%EB%A1%9C-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0-%EA%B8%B0%EC%B4%88" id="markdown-toc-keras로-구현하기-기초">Keras로 구현하기 (기초)</a><ol>
<li><a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%80%EB%B9%84" id="markdown-toc-데이터-준비">데이터 준비</a></li>
<li><a href="#normalizer-%EC%A4%80%EB%B9%84" id="markdown-toc-normalizer-준비">Normalizer 준비</a></li>
<li><a href="#%EB%AA%A8%EB%8D%B8-%ED%98%95%EC%84%B1" id="markdown-toc-모델-형성">모델 형성</a></li>
<li><a href="#%ED%95%99%EC%8A%B5--%ED%8F%89%EA%B0%80" id="markdown-toc-학습--평가">학습 &amp; 평가</a></li>
</ol>
</li>
</ol></details><hr>
<p>*<u>Deep Learning</u>: ML 연구방법 중 하나로, Neural Network를 활용하는 방식.</p>
<p class="fs-1 lh-0"> </p>
<p>*python으로 Deep Learning을 할 때 사용할 수 있는 framework:</p>
<ul>
<li>Tensorflow: Google에서 개발</li>
<li>Keras: tensorflow를 기반으로 만든, 보다 쉬운 framework<ul>
<li>입문자용으로 적합. 전문 연구자가 아니고 본인 필드에 가볍게 응용하는 정도면 Keras로 충분</li>
<li>TensorFlow v1.10.0부터 tf.keras로 텐서플로우 안에서 케라스를 사용</li>
</ul>
</li>
<li>PyTorch: Facebook에서 개발</li>
</ul>
<h2 id="인공신경망-이론"> <a href="#%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D-%EC%9D%B4%EB%A1%A0" aria-labelledby="인공신경망-이론" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 인공신경망 이론</h2>
<h3 id="neural-network의-구조"> <a href="#neural-network%EC%9D%98-%EA%B5%AC%EC%A1%B0" aria-labelledby="neural-network의-구조" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Neural network의 구조</h3>
<p>※ layer의 수를 셀 때, 보통 hidden layer와 output layer 수로 표현. (input layer는 0번째 층으로 간주) <br> → L = 3이면 hidden layer 2개에 output layer 1개인 구조</p>
<p>※ 각 layer에 포함된 node들을 neuron이라고도 함 (인공 뉴런)</p>
<p class="fs-1 lh-0"> </p>
<p class="fs-2 text-grey-dk-000"><img src="../../../assets/images/machine_learning/neural_network_example.png" alt="Neural_Network_Example" width="550"> <br> (출처: dzone.com)</p>
<p class="fs-1 lh-0"> </p>
<p><strong>1. Input layer</strong> <br> : 입력층. 가장 앞에 있는 레이어로, 독립변수를 데이터로 받는다.</p>
<ul><li>독립변수(feature)의 수만큼의 input node로 구성 (각 node는 각 독립변수의 값을 입력받음)<ul><li>ex) 두 개의 독립변수(평수, 연식)을 통해 아파트 가격을 예측할 경우, input node는 2개</li></ul>
</li></ul>
<p><strong>2. Hidden layer</strong><br> : 은닉층. 추가적인 작업을 통해 종속변수의 정확한 예측에 기여하는 node들을 뽑아낸다.</p>
<ul>
<li>앞 layer에 존재하는 정보들 중 종속변수 예측에 중요한 정보들을 추출해주는 역할을 한다.</li>
<li>hidden layer는 1개 이상 존재할 수 있다. (연구자가 결정하는 것)</li>
<li>hidden layer가 너무 많아도 오히려 성능이 떨어지기에, 보통 1-3개 사이 중에서 고르는 듯?</li>
<li>보통 hidden layer 수가 많은 경우를 ‘deep neural networks’ = ‘deep learning’이라고 부르는 것.</li>
<li>hidden layer의 node 개수도 연구자 재량에 따라 결정.</li>
<li>첫번째 hidden layer의 node 수와 두번째 hidden layer의 node 수가 같지 않아도 됨. 하지만 보통은 그 전 layer의 node 수와 같거나 적은 수를 사용한다고 함</li>
<li>hidden layer의 node 수는 보통 input layer의 node 수와 output layer의 node 수 사이로 많이 설정</li>
</ul>
<p><strong>3. Output layer</strong><br> : 출력층. 종속변수에 대한 예측치가 출력되는 레이어.</p>
<ul><li>종속변수의 형태에 따라 output node 수가 달라짐<ul>
<li>이분적 분류 문제: output node를 2개로 하거나 / 1개로 두고, 시그모이드 함수를 output layer의 활성 함수로 사용해 0에 가까운지 1에 가까운지를 가지고 판단</li>
<li>다중 분류 문제: 결과변수(DV)가 취할 수 있는 값 (카테고리의 수) = output node의 수</li>
<li>회귀 문제: output node는 1개. (예측치 = output node)</li>
</ul>
</li></ul>
<p><strong>+) Bias Node</strong></p>
<ul>
<li>bias node = intercept (상수항)의 개념 (선형회귀에서의 intercept의 기능과 같다)</li>
<li>input layer와 hidden layer에만 bias node가 하나씩 들어갈 수 있으며, bias node가 들어가면 모델의 flexibility가 증가한다.</li>
</ul>
<p><strong>+) Weights (Parameters)</strong></p>
<ul>
<li>독립변수와 종속변수 간의 관계를 설정 (선형회귀에서의 theta값과 동일한 기능)</li>
<li>node와 node를 잇는 각 선마다 별도의 weight가 존재.<ul><li>ex) 1번째 layer의 모든 node와 2번째 layer의 모든 node 간에는 별도의 weight가 존재</li></ul>
</li>
</ul>
<p class="fs-1 lh-0"> </p>
<h3 id="가설함수와-손실함수"> <a href="#%EA%B0%80%EC%84%A4%ED%95%A8%EC%88%98%EC%99%80-%EC%86%90%EC%8B%A4%ED%95%A8%EC%88%98" aria-labelledby="가설함수와-손실함수" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 가설함수와 손실함수</h3>
<ul>
<li>가설함수: 주어진 가중치(weight)와 편향(bias)에 따라 output layer 뉴런들의 출력을 계산해내는 함수.</li>
<li>손실함수(비용함수):<ul>
<li>회귀 문제: 보통 MSE(평균제곱오차)를 많이 사용</li>
<li>분류 문제: 보통 로그 손실(cross entropy)를 많이 사용</li>
</ul>
</li>
</ul>
<p>→ 경사하강법을 사용해서 손실함수의 최소점을 찾는다. (손실함수를 최소화하는 weight 값들을 구한다)</p>
<p class="fs-1 lh-0"> </p>
<p><strong>+) 다양한 경사 하강법</strong></p>
<ul>
<li>배치 경사 하강법 (batch gradient descent):<ul><li>한 번 경사 하강을 할 때 모든 학습 데이터를 사용 → 데이터가 많으면 너무 오래 걸린다!</li></ul>
</li>
<li>확률적 경사 하강법 (stochastic gradient descent):<ul><li>한 번 경사 하강을 할 때 하나의 학습 데이터만 사용 → 빠르게 계산이 가능하지만, 가장 경사가 가파른 방향으로 하강하지 않으며 극소점 근처에서도 계속 주변을 맴돌며 쉽게 수렴하지 않을 수 있다는 단점도 있음</li></ul>
</li>
<li>미니 배치 경사 하강법 (mini batch gradient descent):<ul><li>위 두가지 방법의 타협점. 데이터셋을 임의로 같은 크기의 여러 데이터셋으로 나눠준 후, 한 번 경사 하강을 할 때 ‘mini batch’ 학습 데이터를 사용 (ex. 학습 데이터를 50개씩 나눠 놓은 후, 한 번의 경사하강에 하나의 mini batch만 사용)</li></ul>
</li>
</ul>
<p>※ 가장 좋은 경사 하강법이 정해져 있는 건 아니지만, 대부분의 경우 미니 배치 경사 하강법을 가장 많이 사용한다</p>
<p class="fs-1 lh-0"> </p>
<h3 id="활성-함수"> <a href="#%ED%99%9C%EC%84%B1-%ED%95%A8%EC%88%98" aria-labelledby="활성-함수" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 활성 함수</h3>
<p>※ hidden &amp; output node들은 보통 입력값 z (이전 층에서 전달하는 입력값)을 그대로 출력하지 않고, 활성화 함수로 변환해 f(z)를 출력한다. (각 node 안에서 이러한 변환이 이루어짐)</p>
<p><img src="../../../assets/images/machine_learning/activation_function_example.png" alt="Activation_Function" width="450"></p>
<p><strong>1. Hidden Layer의 활성 함수</strong></p>
<p class="fs-2 text-grey-dk-000"><img src="../../../assets/images/machine_learning/activation_function_types.png" alt="Activation_Function_3Types"> (출처: adilmoujahid.com)</p>
<ul>
<li>시그모이드 함수( = logistic function)<ul><li>$ \frac{1}{(1 + e^{-z})} $로 계산. input을 0~1 사이의 숫자로 바꿔서 출력해주게 됨</li></ul>
</li>
<li>Hyperbolic tangent (tanh)<ul><li>$ \frac{sinh(z)}{cosh(z)} = \frac{(e^z - e^{-z})}{(e^z + e^{-z})} $로 계산. input을 -1 ~ 1 사이의 값으로 바꿔서 출력해줌</li></ul>
</li>
<li>ReLU (Rectified Linear Unit)<ul>
<li>
<code class="language-plaintext highlighter-rouge">max(0, z)</code>로 계산. input이 0보다 크면 그대로 출력, 0보다 작거나 같으면 0을 출력.</li>
<li>경사 계산 속도가 매우 빠르다는 장점. (z가 0보다 크면 경사가 1, 작거나 같으면 0)</li>
</ul>
</li>
<li>Leaky ReLU<ul>
<li>ReLU를 약간 변형한 형태로, 사라지는 기울기 문제가 덜해진다.</li>
<li>
<code class="language-plaintext highlighter-rouge">max(εz, z)</code>로 계산. ε(입실론)은 보통 0.01 정도의 작은 상수를 사용</li>
</ul>
</li>
</ul>
<p>※ 최근에는 hidden layer의 활성 함수로 ReLU가 가장 많이 사용된다.</p>
<p>※ 활성화 함수가 비선형이면 신경망도 비선형 함수, 활성화 함수가 선형이면 신경망도 결국 선형 함수 (선형적인 결정경계만 찾아낼 수 있음) → 은닉층의 활성 함수로는 선형 함수를 사용하지 않는다!</p>
<p><strong>2. Output Layer의 활성 함수</strong></p>
<ul>
<li>분류문제 (DV가 분류문제)<ul>
<li>이분적 분류 문제라면 보통 output layer의 활성함수로 ‘시그모이드 함수’를 사용.<ul><li>output node를 1개만 두고, 0에 가까운지 1에 가까운지의 ‘확률’에 따라 분류</li></ul>
</li>
<li>다중 분류 문제라면 보통 ‘Softmax 함수’를 사용.<ul>
<li>$ \frac{e^z}{각 node의 e^z의 합} $으로 계산 (e는 자연상수. 2.71…) → 그리고 가장 값이 큰 쪽으로 분류</li>
<li>※ Softmax 함수는 늘 출력값의 합이 1이 되기에, 다중 분류에서 보다 확률적으로 의미가 명확하다 (ex. 강아지일 확률 70%)</li>
</ul>
</li>
</ul>
</li>
<li>회귀문제 (DV가 연속변수): output layer의 활성함수로 ‘선형함수’를 사용. output node를 1개만 두고, output node가 받는 z값을 그대로 출력. (output layer에 활성함수가 없다고 이해해도 무방)</li>
</ul>
<h2 id="keras로-구현하기-기초"> <a href="#keras%EB%A1%9C-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0-%EA%B8%B0%EC%B4%88" aria-labelledby="keras로-구현하기-기초" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Keras로 구현하기 (기초)</h2>
<ul>
<li>먼저, 설치해야 사용이 가능하다: <a href="https://www.tensorflow.org/install/pip#virtual-environment-install" target="_blank">https://www.tensorflow.org/install/pip#virtual-environment-install</a>
</li>
<li>google colaboratory에서는 별도의 설치 없이 바로 import해서 사용 가능</li>
</ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>  <span class="c1"># google colab에서는 설치 따로 안해도 import해서 사용 가능
</span><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers.experimental</span> <span class="kn">import</span> <span class="n">preprocessing</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Make numpy printouts easier to read.
</span><span class="n">np</span><span class="p">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">suppress</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  
</code></pre></div></div>
<ul>
<li>precision=2: 소수점 두번째 자리까지만 출력</li>
<li>suppress=True: e-04와 같은 scientific notation을 제거</li>
</ul>
<h3 id="데이터-준비"> <a href="#%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A4%80%EB%B9%84" aria-labelledby="데이터-준비" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 데이터 준비</h3>
<ul><li>기초 예시이기에, 기본으로 제공되는 boston_housing 데이터를 사용</li></ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow.keras.datasets</span> <span class="kn">import</span> <span class="n">boston_housing</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">boston_housing</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>   <span class="c1"># test_split=0.2이 default.
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz
57344/57026 [==============================] - 0s 0us/step
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1">## train:test가 대략 4:1 비율로 나뉘었고, IV는 13개, DV는 1개 
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(404, 13) (404,) (102, 13) (102,)
</code></pre></div></div>
<h3 id="normalizer-준비"> <a href="#normalizer-%EC%A4%80%EB%B9%84" aria-labelledby="normalizer-준비" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Normalizer 준비</h3>
<ul><li>preprocessing을 위한 normalization layer를 준비해서 모델에 넣게 됨</li></ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">normalizer</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">Normalization</span><span class="p">()</span>
<span class="n">normalizer</span><span class="p">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>

<span class="c1"># 아래와 같이 normalizer에 13개 IV 각각의 평균(mean)과 분산(variance) 정보가 저장됨
</span><span class="k">print</span><span class="p">(</span><span class="n">normalizer</span><span class="p">.</span><span class="n">mean</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">normalizer</span><span class="p">.</span><span class="n">variance</span><span class="p">.</span><span class="n">numpy</span><span class="p">())</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[  3.75  11.48  11.1    0.06   0.56   6.27  69.01   3.74   9.44 405.9
  18.48 354.78  12.74]
[   85.18   563.51    46.28     0.06     0.01     0.5    778.75     4.11
    75.47 27611.97     4.83  8834.99    52.5 ]
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">## 예시로, 데이터를 넣었을 때 잘 normalize되는지 확인
</span>
<span class="n">ex_array</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>   <span class="c1"># X_train의 첫번째 값 (첫번째 도시에 대한 13개 정보 vector)
</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Original:'</span><span class="p">,</span> <span class="n">ex_array</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Normalized:'</span><span class="p">,</span> <span class="n">normalizer</span><span class="p">(</span><span class="n">ex_array</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span>  <span class="c1"># 원래 서로 다른 scale의 값이였지만 잘 normalize된 것을 확인 가능!
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Original: [[  1.23   0.     8.14   0.     0.54   6.14  91.7    3.98   4.   307.
   21.   396.9   18.72]]
Normalized: [[-0.27 -0.48 -0.44 -0.26 -0.17 -0.18  0.81  0.12 -0.63 -0.6   1.15  0.45
   0.83]]
</code></pre></div></div>
<h3 id="모델-형성"> <a href="#%EB%AA%A8%EB%8D%B8-%ED%98%95%EC%84%B1" aria-labelledby="모델-형성" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 모델 형성</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">normalizer</span><span class="p">,</span>
    <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)),</span>   <span class="c1"># hidden layer 1
</span>    <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>   <span class="c1"># hidden layer 2
</span>    <span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>   <span class="c1"># output layer: 회귀 문제이므로 node 1개 &amp; 활성 함수 지정 X                        
</span><span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
normalization (Normalization (None, 13)                27        
_________________________________________________________________
dense_6 (Dense)              (None, 64)                896       
_________________________________________________________________
dense_7 (Dense)              (None, 32)                2080      
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 33        
=================================================================
Total params: 3,036
Trainable params: 3,009
Non-trainable params: 27
_________________________________________________________________
</code></pre></div></div>
<p>*Prameter 수 계산:</p>
<ul>
<li>첫번째 normalization layer는 13*2 + 1 = 27</li>
<li>두번째: 14 * 64 = 896 (bias node가 하나씩 추가되니까 13이 아니라 14)</li>
<li>세번째: 65 * 32 = 2080</li>
<li>마지막: 33 * 1 = 33</li>
</ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">MeanSquaredError</span><span class="p">(),</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
</code></pre></div></div>
<ul>
<li>손실함수: 보통 ‘mean_absolute_error’나 keras.losses.MeanSquaredError() 사용</li>
<li>optimizer로 어떤 경사 하강법을 사용할지 결정. 보통 Adam(Adaptive Moment Estimation)을 많이 사용</li>
<li>Adam(0.01): learning_rate를 0.01로 지정한 것. (default = 0.001)</li>
<li>Adam 경사하강법은 파라미터에 따라 learning rate를 자동으로 조절해주는 기능이 있으나, 초기 learning rate는 설정을 해줘야 함</li>
</ul>
<h3 id="학습--평가"> <a href="#%ED%95%99%EC%8A%B5--%ED%8F%89%EA%B0%80" aria-labelledby="학습--평가" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 학습 &amp; 평가</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
    <span class="n">validation_split</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>   <span class="c1"># 20%의 trainig data를 validation data로 사용 -- 사실 이미 train_test_split을 해뒀기 때문에 꼭 할 필요는 없다.
</span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>  <span class="c1"># 전체 데이터를 몇 번 반복해서 업데이트할 것인지
</span>    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>  <span class="c1"># 한 번 업데이트할 때 데이터포인트를 몇 개 사용할지
</span>    <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>  <span class="c1"># 학습 과정을 아래에 출력하지 않겠다는 의미
</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>CPU times: user 10.2 s, sys: 432 ms, total: 10.6 s
Wall time: 9.49 s
</code></pre></div></div>
<ul>
<li>batch_size: default는 32. 보통 2의 배수를 많이 사용하는 듯.</li>
<li>verbose: 0, 1, 2 중 하나 선택. 0 = silent, 1 = progress bar, 2 = one line per epoch</li>
</ul>
<p>+) batch_size와 epoch:</p>
<ul><li>ex) 학습 데이터가 48개 있고, batch_size=16, epochs=100이라면, 총 (48/16) * 100 = 300번 업데이트가 일어남<ul><li>48개의 데이터를 16개씩 쪼개서 3번 나눠서 업데이트를 해주는데, 이렇게 전체 데이터를 업데이트하는 과정을 100번 반복하는 것!</li></ul>
</li></ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_loss</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'loss'</span><span class="p">)</span>    <span class="c1">## 실제 training에 사용했던 data에서 어느 정도 오차가 발생하는지
</span>  <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s">'val_loss'</span><span class="p">)</span>   <span class="c1">## validation data로 사용했던 20%에서 어느 정도 오차가 발생하는지
</span>  <span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Epoch'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Loss'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>


<span class="n">plot_loss</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/deep_learning_loss_history.png" alt="Deep_Learning_Loss_History"></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># test data로 예측했을 때의 손실 확인
</span><span class="n">model</span><span class="p">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4/4 [==============================] - 0s 2ms/step - loss: 13.1361
13.136137008666992
</code></pre></div></div>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">r2_score</span>

<span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>   <span class="c1"># r스퀘어값 확인
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.8421969063118736
</code></pre></div></div>
<hr>
<footer><p class="text-small text-grey-dk-000 mb-0">Copyright © 2021 Chaeyun.<br>This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a Jekyll theme.</p></footer>
</div>
</div>
<div class="search-overlay"></div>
</div>
</body>
</html>
