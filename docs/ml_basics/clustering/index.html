<!DOCTYPE html>
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<link rel="shortcut icon" href="https://chaelist.github.io/assets/images/cat.png" type="image/x-icon">
<link rel="stylesheet" href="https://chaelist.github.io/assets/css/just-the-docs-default.css"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-QJ6H6890X3"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-QJ6H6890X3'); </script> <script type="text/javascript" src="https://chaelist.github.io/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="https://chaelist.github.io/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1">
<title>Clustering | chaelist</title>
<meta name="generator" content="Jekyll v4.2.1">
<meta property="og:title" content="Clustering">
<meta property="og:locale" content="en_US">
<meta name="description" content="chaelist’s blog">
<meta property="og:description" content="chaelist’s blog">
<link rel="canonical" href="https://chaelist.github.io/docs/ml_basics/clustering/">
<meta property="og:url" content="https://chaelist.github.io/docs/ml_basics/clustering/">
<meta property="og:site_name" content="chaelist">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="Clustering"> <script type="application/ld+json"> {"description":"chaelist’s blog","url":"https://chaelist.github.io/docs/ml_basics/clustering/","@type":"WebPage","headline":"Clustering","@context":"https://schema.org"}</script>
</head>
<body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewbox="0 0 24 24"><title>Link</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewbox="0 0 24 24"><title>Search</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewbox="0 0 24 24"><title>Menu</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewbox="0 0 24 24"><title>Expand</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewbox="0 0 24 24"><title>Document</title>
<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewbox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar">
<div class="site-header"> <a href="https://chaelist.github.io/" class="site-title lh-tight"> chaelist </a> <a href="#" id="menu-button" class="site-button"> <svg viewbox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a>
</div>
<nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list">
<li class="nav-list-item"><a href="https://chaelist.github.io/" class="nav-list-link">Home</a></li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/python_basics" class="nav-list-link">Python 기초</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/python_basics/numbers_list_string/" class="nav-list-link">Numbers, List, String</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/python_basics/dictionary_tuple_set/" class="nav-list-link">Dictionary, Tuple, Set</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/python_basics/controlflow/" class="nav-list-link">Control Flow (제어문)</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/python_basics/function_module/" class="nav-list-link">Function &amp; Module</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/data_handling" class="nav-list-link">Data Handling</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/file_input_output/" class="nav-list-link">파일 읽고 쓰기</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/file_folder_handling/" class="nav-list-link">파일 &amp; 폴더 다루기</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/regular_expressions/" class="nav-list-link">Regular Expressions</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/useful_functions/" class="nav-list-link">유용한 Python 내장함수</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/data_handling/datetime/" class="nav-list-link">Datetime 다루기</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/numpy" class="nav-list-link">Numpy</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/numpy/numpy_basics/" class="nav-list-link">Numpy 기초</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/numpy/numpy_arithmetics/" class="nav-list-link">Numpy 연산과 통계</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/pandas" class="nav-list-link">Pandas</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_basics/" class="nav-list-link">Pandas 기초</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_data_modifying/" class="nav-list-link">Pandas 데이터 가공</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_data_analysis/" class="nav-list-link">Pandas 데이터 분석</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_merge_group/" class="nav-list-link">Pandas 데이터 결합 &amp; 요약</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/pandas/pandas_str_dt_con/" class="nav-list-link">Pandas str, dt, 조건문</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/visualization" class="nav-list-link">데이터 시각화</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/visualization/pandas_plot/" class="nav-list-link">Pandas plot() 함수</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/visualization/seaborn/" class="nav-list-link">Seaborn</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/visualization/matplotlib/" class="nav-list-link">Matplotlib</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/visualization/plotly/" class="nav-list-link">Plotly</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/webscraping" class="nav-list-link">Web Scraping</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/requests_beautifulsoup/" class="nav-list-link">Requests &amp; BeautifulSoup</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/selenium/" class="nav-list-link">Selenium</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/image_api/" class="nav-list-link">Image 수집 &amp; API 활용</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/twitter_api/" class="nav-list-link">Twitter 데이터 수집</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/webscraping/app_review/" class="nav-list-link">App Review 수집</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/text_analysis" class="nav-list-link">Text 분석</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/text_analysis/english_text/" class="nav-list-link">빈도 분석 (English)</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/text_analysis/korean_text/" class="nav-list-link">빈도 분석 (한글)</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/network_analysis" class="nav-list-link">Network Analysis</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/network_analysis/network_basics/" class="nav-list-link">Network Analysis 기초</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/network_analysis/social_network/" class="nav-list-link">Social Network Analysis</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/network_analysis/semantic_network/" class="nav-list-link">Semantic Network Analysis</a></li>
</ul>
</li>
<li class="nav-list-item active">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/ml_basics" class="nav-list-link">Machine Learning 기초</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_basics/linear_regression/" class="nav-list-link">기초 &amp; Linear Regression</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_basics/classification1/" class="nav-list-link">Classification 1</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_basics/classification2/" class="nav-list-link">Classification 2</a></li>
<li class="nav-list-item active"><a href="https://chaelist.github.io/docs/ml_basics/clustering/" class="nav-list-link active">Clustering</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_basics/deep_learning/" class="nav-list-link">Deep Learning 기초</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/ml_advanced" class="nav-list-link">Machine Learning 심화</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_advanced/regularization/" class="nav-list-link">Regularization</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_advanced/preprocessing/" class="nav-list-link">데이터 전처리</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_advanced/model_selection/" class="nav-list-link">Model Selection</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/ml_application" class="nav-list-link">Machine Learning 응용</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/sentiment_analysis/" class="nav-list-link">영화 리뷰 감성 분석</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/news_clustering/" class="nav-list-link">뉴스 기사 Clustering</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/time_series/" class="nav-list-link">시계열 데이터 예측</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/topic_modeling/" class="nav-list-link">Topic Modeling (LDA)</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/logistics/" class="nav-list-link">물류 최적화</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/ml_application/image_processing/" class="nav-list-link">이미지 / 동영상 처리</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/sql" class="nav-list-link">SQL</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/select_basics/" class="nav-list-link">데이터 조회 기초</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/select_advanced/" class="nav-list-link">데이터 조회 심화</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/join_subq_view/" class="nav-list-link">조인, 서브쿼리, 뷰</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/db_table_create/" class="nav-list-link">데이터베이스 &amp; 테이블 구축</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/modify_table/" class="nav-list-link">테이블 가공</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/sql/foreign_key_pymysql/" class="nav-list-link">Foreign Key &amp; Python 연결</a></li>
</ul>
</li>
<li class="nav-list-item">
<a href="#" class="nav-list-expander"><svg viewbox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="https://chaelist.github.io/docs/kaggle" class="nav-list-link">Kaggle Dataset EDA</a><ul class="nav-list ">
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/youtube_trending/" class="nav-list-link">YouTube Trending Videos</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/amazon_bestsellers/" class="nav-list-link">Amazon Bestselling Books</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/customer_churn/" class="nav-list-link">Telco Customer Churn</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/kiva_crowdfunding/" class="nav-list-link">Kiva Crowdfunding 1</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/kiva_crowdfunding2/" class="nav-list-link">Kiva Crowdfunding 2</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/stem_salaries/" class="nav-list-link">STEM Salaries 1</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/stem_salaries2/" class="nav-list-link">STEM Salaries 2</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/uk_ecommerce/" class="nav-list-link">UK Ecommerce Data 1</a></li>
<li class="nav-list-item "><a href="https://chaelist.github.io/docs/kaggle/uk_ecommerce2/" class="nav-list-link">UK Ecommerce Data 2</a></li>
</ul>
</li>
</ul></nav><footer class="site-footer"></footer>
</div>
<div class="main" id="top">
<div id="main-header" class="main-header"><div class="search">
<div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search chaelist" aria-label="Search chaelist" autocomplete="off"> <label for="search-input" class="search-label"><svg viewbox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
</div>
<div id="search-results" class="search-results"></div>
</div></div>
<div id="main-content-wrap" class="main-content-wrap">
<nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list">
<li class="breadcrumb-nav-list-item"><a href="https://chaelist.github.io/docs/ml_basics">Machine Learning 기초</a></li>
<li class="breadcrumb-nav-list-item"><span>Clustering</span></li>
</ol></nav><div id="main-content" class="main-content" role="main">
<h1 class="no_toc" id="clustering"> <a href="#clustering" aria-labelledby="clustering" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Clustering</h1>
<p><br></p>
<details open=""> <summary class="text-delta"> Table of contents </summary><ol id="markdown-toc">
<li><a href="#clustering-1" id="markdown-toc-clustering-1">Clustering</a></li>
<li>
<a href="#k-means-clustering" id="markdown-toc-k-means-clustering">K-Means Clustering</a><ol>
<li><a href="#%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90" id="markdown-toc-기본-개념">기본 개념</a></li>
<li><a href="#scikit-learn%EC%9C%BC%EB%A1%9C-%EA%B5%AC%ED%98%84" id="markdown-toc-scikit-learn으로-구현">scikit-learn으로 구현</a></li>
<li><a href="#%EC%B5%9C%EC%A0%81%EC%9D%98-k%EA%B0%92-%EC%B0%BE%EA%B8%B0" id="markdown-toc-최적의-k값-찾기">최적의 K값 찾기</a></li>
<li><a href="#%EC%B5%9C%EC%A0%81%EC%9D%98-k%EA%B0%92-%EC%B0%BE%EA%B8%B0-yellowbrick" id="markdown-toc-최적의-k값-찾기-yellowbrick">최적의 K값 찾기: yellowbrick</a></li>
</ol>
</li>
<li>
<a href="#hierarchical-clustering" id="markdown-toc-hierarchical-clustering">Hierarchical Clustering</a><ol>
<li><a href="#%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90-1" id="markdown-toc-기본-개념-1">기본 개념</a></li>
<li><a href="#dendrogram-%EA%B7%B8%EB%A0%A4%EB%B3%B4%EA%B8%B0" id="markdown-toc-dendrogram-그려보기">Dendrogram 그려보기</a></li>
<li><a href="#scikit-learn%EC%9C%BC%EB%A1%9C-%EA%B5%AC%ED%98%84-1" id="markdown-toc-scikit-learn으로-구현-1">scikit-learn으로 구현</a></li>
<li><a href="#%EC%B5%9C%EC%A0%81%EC%9D%98-k%EA%B0%92-%EC%B0%BE%EA%B8%B0-yellowbrick-1" id="markdown-toc-최적의-k값-찾기-yellowbrick-1">최적의 K값 찾기: yellowbrick</a></li>
</ol>
</li>
</ol></details><hr>
<h2 id="clustering-1"> <a href="#clustering-1" aria-labelledby="clustering-1" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Clustering</h2>
<p>: 거리를 계산해 유사한 data point끼리 같은 Cluster로 묶어주는 것.</p>
<ul>
<li>비지도학습. 종속변수가 없고, 독립변수만 사용해서 답을 찾는 방식.</li>
<li>대체로 탐색적 데이터 분석의 일부로 수행된다. (ex. 소비자 Cluster를 나눈 후 → 어떤 Cluster가 A제품을 많이 사는지 Regression 문제 풀기)</li>
</ul>
<h2 id="k-means-clustering"> <a href="#k-means-clustering" aria-labelledby="k-means-clustering" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> K-Means Clustering</h2>
<h3 id="기본-개념"> <a href="#%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90" aria-labelledby="기본-개념" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 기본 개념</h3>
<ul>
<li>데이터 포인트 (벡터) 간의 거리를 계산해, 거리가 짧은 애들끼리 묶어 K개의 Cluster를 형성해주는 방식.</li>
<li>K 값을 잘 정해주는 것이 중요하다!</li>
<li>보통 유클리디안 방식으로 거리를 계산.</li>
</ul>
<p class="fs-2 text-grey-dk-000"><img src="../../../assets/images/machine_learning/kmeans_example.png" alt="K-Means_example" width="500"><br> (출처: tcpschool.com)</p>
<p class="fs-1 lh-0"> </p>
<p><strong>*K-Means Clustering 과정:</strong></p>
<ol>
<li>K의 값을 정한다 (몇 개의 Cluster로 나눌 것인지)</li>
<li>데이터셋에서 임의로 K개의 중심점을 선택.</li>
<li>각 점을 K개의 중심점 중 가장 가까운 점이 속한 Cluster로 assign.</li>
<li>각 그룹에 속하는 점들의 평균값을 새로운 중심점으로 함.</li>
<li>색이 변하는 점이 없을 때까지 3, 4번을 계속 반복.</li>
</ol>
<h3 id="scikit-learn으로-구현"> <a href="#scikit-learn%EC%9C%BC%EB%A1%9C-%EA%B5%AC%ED%98%84" aria-labelledby="scikit-learn으로-구현" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> scikit-learn으로 구현</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div></div>
<p><strong>1. 데이터 준비</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 예시이므로, make_blobs를 사용해 clustering하기 쉬운 데이터를 준비
</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>   <span class="c1"># 변수 2개, 샘플 100개, 중심점 3개로 blob 만들기
</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'a'</span><span class="p">,</span> <span class="s">'b'</span><span class="p">])</span>
<span class="n">X</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<div class="code-example"><div class="table-wrapper"><table>
<thead><tr>
<th style="text-align: right"> </th>
<th style="text-align: right">a</th>
<th style="text-align: right">b</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align: right">0</td>
<td style="text-align: right">8.66962</td>
<td style="text-align: right">-2.95918</td>
</tr>
<tr>
<td style="text-align: right">1</td>
<td style="text-align: right">-10.3818</td>
<td style="text-align: right">0.959058</td>
</tr>
<tr>
<td style="text-align: right">2</td>
<td style="text-align: right">9.45125</td>
<td style="text-align: right">-2.50409</td>
</tr>
<tr>
<td style="text-align: right">3</td>
<td style="text-align: right">-4.03838</td>
<td style="text-align: right">-9.18607</td>
</tr>
<tr>
<td style="text-align: right">4</td>
<td style="text-align: right">10.9778</td>
<td style="text-align: right">-2.85563</td>
</tr>
</tbody>
</table></div></div>
<p class="fs-1 lh-0"> </p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">"a"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"b"</span><span class="p">);</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/kmeans_data.png" alt="K-Means_data"></p>
<p><strong>2. Clustering</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>
<ul><li>n_clusters: 몇 개의 cluster로 나눌 것인지 설정 (K)</li></ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,
       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',
       random_state=None, tol=0.0001, verbose=0)
</code></pre></div></div>
<ul>
<li>init: initialization 방법. <code class="language-plaintext highlighter-rouge">k-means++</code>, <code class="language-plaintext highlighter-rouge">random</code>, 혹은 직접 array 형태로 지정<ul>
<li>default는 k-means++. 맨 처음 중심점을 보다 전략적으로 배치하는 방식.<ul>
<li>우선 데이터포인트 1개를 첫번째 중심점으로 선택하고, 이와 최대한 먼 곳에 있는 데이터포인트를 다음 중심점으로 선택, …</li>
<li>맨 처음 중심점들이 서로 근접하게 위치하는 것을 방지해주기 때문에 단순히 random하게 고르는 것보다 더 최적의, 효율적인 clustering이 가능하다</li>
</ul>
</li>
<li>random: 맨 처음 중심점을 말 그대로 무작위로 K개 고르는 방식</li>
</ul>
</li>
<li>max_iter: 중심과 다른 데이터포인트 간의 거리를 계산해서 계속해서 cluster를 update해주는 것을 최대 몇 번 반복할 것인지 지정. max_iter 수를 작게 지정해주면 속도가 빨라지지만 정확도는 떨어짐. default=300</li>
<li>n_init: 서로 다른 초기 중심점을 바탕으로 몇 번 알고리즘을 반복할 것인지 지정. default=10. 최종 결과는 inertia 계산값이 가장 잘 나오는 결과물로 출력됨.<ul><li>inertia: 클러스터 내 오차제곱합. Sum of squared distances of samples to their closest cluster center.</li></ul>
</li>
</ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clusters</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># model.labels_라고 해도 동일한 결과
</span><span class="n">clusters</span>  <span class="c1"># 각 점이 어느 cluster에 배정되었는지 확인
</span></code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([0, 1, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 0, 1, 0, 0, 1, 1, 1, 1, 2, 0,
       1, 1, 1, 2, 2, 1, 0, 1, 1, 1, 2, 2, 1, 0, 0, 1, 2, 1, 2, 2, 0, 1,
       2, 2, 1, 1, 2, 1, 2, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,
       0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 2, 2, 1, 0, 2, 0, 2, 1, 2, 0, 2, 2,
       2, 2, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1], dtype=int32)
</code></pre></div></div>
<ul><li>
<code class="language-plaintext highlighter-rouge">clusters = model.fit_predict(X)</code>라고 하면 fit과 predict를 동시에 할 수 있음. (clustering은 사실 fit과 predict가 하나의 과정이라서)</li></ul>
<p><strong>3. Clustering 결과 확인</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">result</span><span class="p">[</span><span class="s">"cluster"</span><span class="p">]</span> <span class="o">=</span> <span class="n">clusters</span>
<span class="n">result</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<div class="code-example"><div class="table-wrapper"><table>
<thead><tr>
<th style="text-align: right"> </th>
<th style="text-align: right">a</th>
<th style="text-align: right">b</th>
<th style="text-align: right">cluster</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align: right">0</td>
<td style="text-align: right">8.66962</td>
<td style="text-align: right">-2.95918</td>
<td style="text-align: right">0</td>
</tr>
<tr>
<td style="text-align: right">1</td>
<td style="text-align: right">-10.3818</td>
<td style="text-align: right">0.959058</td>
<td style="text-align: right">1</td>
</tr>
<tr>
<td style="text-align: right">2</td>
<td style="text-align: right">9.45125</td>
<td style="text-align: right">-2.50409</td>
<td style="text-align: right">0</td>
</tr>
<tr>
<td style="text-align: right">3</td>
<td style="text-align: right">-4.03838</td>
<td style="text-align: right">-9.18607</td>
<td style="text-align: right">2</td>
</tr>
<tr>
<td style="text-align: right">4</td>
<td style="text-align: right">10.9778</td>
<td style="text-align: right">-2.85563</td>
<td style="text-align: right">0</td>
</tr>
</tbody>
</table></div></div>
<p class="fs-1 lh-0"> </p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">result</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">"a"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"b"</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">"cluster"</span><span class="p">,</span> <span class="n">palette</span><span class="o">=</span><span class="s">"Set2"</span><span class="p">);</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/kmeans_result.png" alt="K-Means_result"></p>
<h3 id="최적의-k값-찾기"> <a href="#%EC%B5%9C%EC%A0%81%EC%9D%98-k%EA%B0%92-%EC%B0%BE%EA%B8%B0" aria-labelledby="최적의-k값-찾기" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 최적의 K값 찾기</h3>
<ul>
<li>make_blobs로 만든 예시 데이터의 경우, 사전에 3개의 분류임을 알고 있었기에 K=3으로 지정해서 진행했지만, 보통은 몇 개의 cluster로 나눠야 할 지 쉽게 알 수 없다.</li>
<li>2차원인 경우, 시각화해서 눈으로 판단하는 것도 가능하지만, 보통의 데이터는 3차원 이상이기에,,, 아래 방식들을 사용하면 좋음!</li>
</ul>
<p class="fs-1 lh-0"> </p>
<p><strong>1. Elbow 방식</strong></p>
<ul>
<li>K값을 1부터 차례로 넣어보면서, 각 결과의 inertia(클러스터 내 오차제곱합)를 구한다</li>
<li>K값에 따른 inertia의 변화를 보고, 그래프의 팔꿈치 부분에 해당하는 지점을 K값으로 선택 (intertia가 감소하는 정도가 낮아지는 지점)</li>
<li>※ inertia는 cluster 수가 증가할 수록 감소함. (trade-off 관계.)</li>
</ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">inertias</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">inertias</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">kmeans</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span> <span class="n">inertias</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Num_Clusters'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Inertia'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span> 

<span class="c1"># 결과: 3이 최적의 Cluster
</span></code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/kmeans_elbow1.png" alt="K-Means_Elbow"></p>
<p><strong>2. Silhouette Score (Silhouette Coefficient)</strong></p>
<ul>
<li>$ \frac{(b-a)}{max(a, b)} $로 계산<ul>
<li>a: 특정한 sample i로부터 같은 Class에 속한 다른 점들까지의 평균 거리 (mean intra-cluster distance)</li>
<li>b: 특정한 sample i로부터 가장 가까운 옆 Class에 속한 점들까지의 평균 거리 (mean nearest-cluster distance)</li>
</ul>
</li>
<li>숫자가 클수록 잘 분류된 것. (숫자가 크다는 것은 타 cluster와는 거리가 있고, 같은 cluster 내에서는 잘 모여 있다는 의미)</li>
</ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span>

<span class="n">silhouette</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">silhouette</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">silhouette_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span> <span class="n">silhouette</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Num_Clusters'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'Silhouette Score'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 결과: 3이 최적의 Cluster
</span></code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/kmeans_silhouette1.png" alt="K-Means_Silhouette_Score"></p>
<p><strong>3. CH Index (Calinski-Harabasz Index)</strong></p>
<ul>
<li>잘 분류된 클러스터는 (1) 내부의 점들끼리 compact하게 모여 있고, (2) 나머지 cluster로부터는 멀리 떨어져있어야 한다는 점에 착안한 Index</li>
<li>$ \frac{BCV}{k-1} * \frac{n-k}{WCV} $로 계산<ul>
<li>BCV: Between-Cluster Variation: 서로 다른 클러스터끼리 얼마나 떨어져있는지. – 클수록 좋음</li>
<li>WCV: Within-Vluster Variation: 서로 같은 클러스터에 있는 점끼리 얼마나 떨어져있는지. – 작을수록 좋음</li>
<li>k: # of clusters</li>
<li>n: # of datapoints</li>
</ul>
</li>
<li>숫자가 클수록 잘 분류된 것. (숫자가 크다는 것은 타 cluster와는 거리가 있고, 같은 cluster 내에서는 잘 모여 있다는 의미)</li>
</ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">calinski_harabasz_score</span>

<span class="n">ch_index</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span>
    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="n">kmeans</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">ch_index</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">calinski_harabasz_score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">kmeans</span><span class="p">.</span><span class="n">labels_</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">11</span><span class="p">),</span> <span class="n">ch_index</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s">'o'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'Num_Clusters'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'CH Index'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># 결과: 3이 최적의 Cluster
</span></code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/kmeans_ch1.png" alt="K-Means_CH_Index"></p>
<h3 id="최적의-k값-찾기-yellowbrick"> <a href="#%EC%B5%9C%EC%A0%81%EC%9D%98-k%EA%B0%92-%EC%B0%BE%EA%B8%B0-yellowbrick" aria-labelledby="최적의-k값-찾기-yellowbrick" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 최적의 K값 찾기: yellowbrick</h3>
<p>*yellowbrick: machine learning visualization library (<a href="https://www.scikit-yb.org/en/latest/" target="_blank">https://www.scikit-yb.org/en/latest/</a>)</p>
<ul><li>최적의 cluster를 자동으로 찾아주고, clustering에 걸리는 시간 등도 간편하게 시각화할 수 있어서 편리하다</li></ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 우선 설치해줘야 사용 가능
</span><span class="kn">import</span> <span class="nn">sys</span>
<span class="err">!</span><span class="p">{</span><span class="n">sys</span><span class="p">.</span><span class="n">executable</span><span class="p">}</span> <span class="o">-</span><span class="n">m</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">yellowbrick</span>  
</code></pre></div></div>
<p><strong>1. Elbow Method</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import ElbowVisualizer
</span><span class="kn">from</span> <span class="nn">yellowbrick.cluster</span> <span class="kn">import</span> <span class="n">KElbowVisualizer</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">()</span>
<span class="n">visualizer</span> <span class="o">=</span> <span class="n">KElbowVisualizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">timings</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>  <span class="c1"># k is range of number of clusters.
</span><span class="n">visualizer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>   <span class="c1"># Fit the data to the visualizer
</span><span class="n">visualizer</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/kmeans_elbow2.png" alt="K-Means_Elbow_YB"></p>
<p><strong>2. Silhouette Score</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">()</span>
<span class="n">visualizer</span> <span class="o">=</span> <span class="n">KElbowVisualizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">metric</span><span class="o">=</span><span class="s">'silhouette'</span><span class="p">,</span> <span class="n">timings</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">visualizer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">visualizer</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/kmeans_silhouette2.png" alt="K-Means_Silhouette_Score_YB"></p>
<p><strong>3. CH Index</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">()</span>
<span class="n">visualizer</span> <span class="o">=</span> <span class="n">KElbowVisualizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">metric</span><span class="o">=</span><span class="s">'calinski_harabasz'</span><span class="p">,</span> <span class="n">timings</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">visualizer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>       
<span class="n">visualizer</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/kmeans_ch2.png" alt="K-Means_CH_Index_YB"></p>
<h2 id="hierarchical-clustering"> <a href="#hierarchical-clustering" aria-labelledby="hierarchical-clustering" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Hierarchical Clustering</h2>
<p>(계층적 군집 분석)</p>
<h3 id="기본-개념-1"> <a href="#%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90-1" aria-labelledby="기본-개념-1" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 기본 개념</h3>
<ul>
<li>K Means와 달리, 중심을 먼저 잡고 시작하는 게 아니라, 일단 모든 벡터의 거리를 다 계산 → 거리가 가장 짧은 것끼리 차근차근 묶어나감. (그룹의 수를 사전에 정하지 않음)</li>
<li>계속 연결해나가서 하나의 완벽한 cluster로 묶일 때까지 묶는 작업을 계속함</li>
<li>Dendrogram 보고 cluster 개수를 얼마 정도로 할 지 고려해서 적당히 잘라줌</li>
</ul>
<p class="fs-1 lh-0"> </p>
<p><strong>*Cluster 간 거리를 계산하는 법:</strong> (※ 데이터포인트 간의 거리는 Euclidean이나 Cosign 방식 등으로 계산)</p>
<ol>
<li>Single: 각 클러스터를 구성하는 데이터포인트 중 가장 가까운 데이터포인트 간의 거리로 계산</li>
<li>Complete: 각 클러스터를 구성하는 데이터포인트 중 가장 먼 데이터포인트 간의 거리로 계산</li>
<li>Average: 각 클러스터를 구성하는 데이터포인트들의 평균점 간의 거리로 계산</li>
<li>Ward: 두 개의 클러스터가 합쳐졌을 때의 데이터포인트들이 갖는 분산 (오차제곱합)이 가장 작은 클러스터끼리 묶어주는 방식</li>
</ol>
<p>※ 4개의 linkage type은 데이터셋의 분포에 따라 결과가 상이하므로, 데이터셋에 따라 적절히 선택</p>
<h3 id="dendrogram-그려보기"> <a href="#dendrogram-%EA%B7%B8%EB%A0%A4%EB%B3%B4%EA%B8%B0" aria-labelledby="dendrogram-그려보기" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Dendrogram 그려보기</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> <span class="n">dendrogram</span><span class="p">,</span> <span class="n">linkage</span>
</code></pre></div></div>
<p><strong>1. 데이터 준비</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># iris dataset 사용 
</span><span class="n">iris_data</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris_data</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris_data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">X</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<div class="code-example"><div class="table-wrapper"><table>
<thead><tr>
<th style="text-align: right"> </th>
<th style="text-align: right">sepal length (cm)</th>
<th style="text-align: right">sepal width (cm)</th>
<th style="text-align: right">petal length (cm)</th>
<th style="text-align: right">petal width (cm)</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align: right">0</td>
<td style="text-align: right">5.1</td>
<td style="text-align: right">3.5</td>
<td style="text-align: right">1.4</td>
<td style="text-align: right">0.2</td>
</tr>
<tr>
<td style="text-align: right">1</td>
<td style="text-align: right">4.9</td>
<td style="text-align: right">3</td>
<td style="text-align: right">1.4</td>
<td style="text-align: right">0.2</td>
</tr>
<tr>
<td style="text-align: right">2</td>
<td style="text-align: right">4.7</td>
<td style="text-align: right">3.2</td>
<td style="text-align: right">1.3</td>
<td style="text-align: right">0.2</td>
</tr>
<tr>
<td style="text-align: right">3</td>
<td style="text-align: right">4.6</td>
<td style="text-align: right">3.1</td>
<td style="text-align: right">1.5</td>
<td style="text-align: right">0.2</td>
</tr>
<tr>
<td style="text-align: right">4</td>
<td style="text-align: right">5</td>
<td style="text-align: right">3.6</td>
<td style="text-align: right">1.4</td>
<td style="text-align: right">0.2</td>
</tr>
</tbody>
</table></div></div>
<p><strong>2. Dendrogram 그려보기</strong></p>
<ul>
<li>Scipy 활용</li>
<li>어떻게 묶일지 시뮬레이션 + 몇 개 Cluster로 나눌지 고민</li>
<li>어떤 linkage type을 쓰면 좋을지, 몇 개의 Cluster를 쓰면 좋을지 고민</li>
</ul>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">L</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s">'single'</span><span class="p">)</span>
<span class="n">dn</span> <span class="o">=</span> <span class="n">dendrogram</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Dendrograms: Single"</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/dendrogram_single.png" alt="Dendrogram_Single"></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="n">L</span> <span class="o">=</span> <span class="n">linkage</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="s">'ward'</span><span class="p">)</span>
<span class="n">dn</span> <span class="o">=</span> <span class="n">dendrogram</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Dendrograms: Ward"</span><span class="p">)</span> 
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/dendrogram_ward.png" alt="Dendrogram_Ward"></p>
<ul>
<li>single로 묶는다면 2개의 cluster로, ward로 묶는다면 2-3개의 cluster로 묶는 게 좋을 것 같다고 판단</li>
<li>complete나 average 방식도 구현해보고 비교해보면 좋음</li>
</ul>
<h3 id="scikit-learn으로-구현-1"> <a href="#scikit-learn%EC%9C%BC%EB%A1%9C-%EA%B5%AC%ED%98%84-1" aria-labelledby="scikit-learn으로-구현-1" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> scikit-learn으로 구현</h3>
<p><strong>3. Clustering</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>   <span class="c1"># iris dataset이므로, n_clusters=3으로 선택
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AgglomerativeClustering(affinity='euclidean', compute_full_tree='auto',
                        connectivity=None, distance_threshold=None,
                        linkage='ward', memory=None, n_clusters=3)
</code></pre></div></div>
<ul>
<li>affinity: 데이터포인트 간의 거리를 어떻게 계산할지 결정. euclidean, cosine, l1, l2, manhattan 중에 고를 수 있으며, default는 euclidean.<ul><li>linkage=’ward’로 하려면 euclidean밖에 선택할 수 없음</li></ul>
</li>
<li>linkage: ward, complete, average, single 중에 선택. (default는 ward)</li>
</ul>
<p><strong>4. Clustering 결과 구현</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">result</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">result</span><span class="p">[</span><span class="s">"cluster"</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">labels_</span>
<span class="n">result</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>
<div class="code-example"><div class="table-wrapper"><table>
<thead><tr>
<th style="text-align: right"> </th>
<th style="text-align: right">sepal length (cm)</th>
<th style="text-align: right">sepal width (cm)</th>
<th style="text-align: right">petal length (cm)</th>
<th style="text-align: right">petal width (cm)</th>
<th style="text-align: right">cluster</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align: right">0</td>
<td style="text-align: right">5.1</td>
<td style="text-align: right">3.5</td>
<td style="text-align: right">1.4</td>
<td style="text-align: right">0.2</td>
<td style="text-align: right">1</td>
</tr>
<tr>
<td style="text-align: right">1</td>
<td style="text-align: right">4.9</td>
<td style="text-align: right">3</td>
<td style="text-align: right">1.4</td>
<td style="text-align: right">0.2</td>
<td style="text-align: right">1</td>
</tr>
<tr>
<td style="text-align: right">2</td>
<td style="text-align: right">4.7</td>
<td style="text-align: right">3.2</td>
<td style="text-align: right">1.3</td>
<td style="text-align: right">0.2</td>
<td style="text-align: right">1</td>
</tr>
<tr>
<td style="text-align: right">3</td>
<td style="text-align: right">4.6</td>
<td style="text-align: right">3.1</td>
<td style="text-align: right">1.5</td>
<td style="text-align: right">0.2</td>
<td style="text-align: right">1</td>
</tr>
<tr>
<td style="text-align: right">4</td>
<td style="text-align: right">5</td>
<td style="text-align: right">3.6</td>
<td style="text-align: right">1.4</td>
<td style="text-align: right">0.2</td>
<td style="text-align: right">1</td>
</tr>
</tbody>
</table></div></div>
<p>+) pairplot으로 clustering이 잘 되었나 살펴보기</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 4차원으로 시각화할 수는 없지만, seaborn의 pairplot으로 어느 정도 다각도로 살펴볼 수는 있음
</span>
<span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">'cluster'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/clustering_iris_pairplot.png" alt="Iris_Clustering_Pairplot"></p>
<h3 id="최적의-k값-찾기-yellowbrick-1"> <a href="#%EC%B5%9C%EC%A0%81%EC%9D%98-k%EA%B0%92-%EC%B0%BE%EA%B8%B0-yellowbrick-1" aria-labelledby="최적의-k값-찾기-yellowbrick-1" class="anchor-heading"><svg viewbox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> 최적의 K값 찾기: yellowbrick</h3>
<ul><li>마찬가지로, iris data처럼 cluster 수를 알고 있는 상황이 아니라면, 아래와 같은 방식들을 사용해 최적의 K값을 찾아보고 clustering을 구현하는 것이 좋다</li></ul>
<p><strong>1. Elbow Method</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Import ElbowVisualizer
</span><span class="kn">from</span> <span class="nn">yellowbrick.cluster</span> <span class="kn">import</span> <span class="n">KElbowVisualizer</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">()</span>
<span class="n">visualizer</span> <span class="o">=</span> <span class="n">KElbowVisualizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">timings</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">visualizer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 
<span class="n">visualizer</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/hierarchical_elbow.png" alt="Hierarchical_Clustering_Elbow"></p>
<p><strong>2. Silhouette Score</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">()</span>
<span class="n">visualizer</span> <span class="o">=</span> <span class="n">KElbowVisualizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">metric</span><span class="o">=</span><span class="s">'silhouette'</span><span class="p">,</span> <span class="n">timings</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">visualizer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">visualizer</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/hierarchical_silhouette.png" alt="Hierarchical_Clustering_Silhouette"></p>
<p><strong>3. CH Index</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">()</span>
<span class="n">visualizer</span> <span class="o">=</span> <span class="n">KElbowVisualizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span> <span class="n">metric</span><span class="o">=</span><span class="s">'calinski_harabasz'</span><span class="p">,</span> <span class="n">timings</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">visualizer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">visualizer</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>
<p><img src="../../../assets/images/machine_learning/hierarchical_ch.png" alt="Hierarchical_Clustering_CH_Index"></p>
<ul><li>대체로 2-3개의 cluster로 나누는 것이 좋다는 결론 (사실 iris data에서 virginica와 versicolor는 꽤 유사하기 때문)</li></ul>
<hr>
<footer><p class="text-small text-grey-dk-000 mb-0">Copyright © 2021 Chaeyun.<br>This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a Jekyll theme.</p></footer>
</div>
</div>
<div class="search-overlay"></div>
</div>
</body>
</html>
